# The Whetstone - Python Dependencies
# For Pro Edition on Radxa Rock 5B+ (Armbian/Ubuntu)

# Core dependencies (always required)
openai>=1.0.0          # OpenAI-compatible API client for Ollama

# Backend: llama.cpp (optional, for direct inference without Ollama)
# Uncomment or install separately with: pip install llama-cpp-python
# For ARM64 (Rock 5B+), you may need to build from source:
#   CMAKE_ARGS="-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS" pip install llama-cpp-python
# llama-cpp-python>=0.2.0

# Future: Vector RAG (Phase 2)
# chromadb>=0.4.0       # Vector database for semantic search
# sentence-transformers>=2.2.0  # Embeddings model

# Future: Voice Integration (Phase 3)
# pyaudio>=0.2.11       # Audio I/O
# numpy>=1.24.0         # Audio processing

# Future: GPIO & Display (Phase 4)
# gpiod>=2.0            # Linux GPIO library (replacing RPi.GPIO)
# Pillow>=10.0.0        # Image processing for e-ink
